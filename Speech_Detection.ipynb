{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":639622,"sourceType":"datasetVersion","datasetId":316368}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-13T16:34:01.942049Z","iopub.execute_input":"2024-01-13T16:34:01.942575Z","iopub.status.idle":"2024-01-13T16:34:01.949398Z","shell.execute_reply.started":"2024-01-13T16:34:01.942538Z","shell.execute_reply":"2024-01-13T16:34:01.948443Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"##Importing modules\n\nimport os\nimport pandas as pd\nimport numpy as np \nimport seaborn as sb\nimport matplotlib.pyplot as plt\nimport librosa\nimport librosa.display \nfrom IPython.display import Audio\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-01-13T21:14:43.237015Z","iopub.execute_input":"2024-01-13T21:14:43.237453Z","iopub.status.idle":"2024-01-13T21:14:43.244222Z","shell.execute_reply.started":"2024-01-13T21:14:43.237419Z","shell.execute_reply":"2024-01-13T21:14:43.242814Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"##Load Data\n\n##Extracting labels\npaths = []\nlabels = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        paths.append((os.path.join(dirname, filename)))\n        label = filename.split('_')[2]\n        label = label.split('.')[0]\n        labels.append(label.lower())\n        \nsetlist = set(labels)\nprint(setlist)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T19:20:20.762727Z","iopub.execute_input":"2024-01-13T19:20:20.763537Z","iopub.status.idle":"2024-01-13T19:20:22.512193Z","shell.execute_reply.started":"2024-01-13T19:20:20.763498Z","shell.execute_reply":"2024-01-13T19:20:22.511095Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"{'disgust', 'ps', 'sad', 'neutral', 'fear', 'happy', 'angry'}\n","output_type":"stream"}]},{"cell_type":"code","source":"## Creating Data frame\n\ndf = pd.DataFrame()\n\ndf['input_path'] = paths\n# speech, label\ndf['emotion_type'] = labels\n\ndf.head()\ndf['emotion_type'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-13T19:20:24.716372Z","iopub.execute_input":"2024-01-13T19:20:24.716780Z","iopub.status.idle":"2024-01-13T19:20:24.750738Z","shell.execute_reply.started":"2024-01-13T19:20:24.716748Z","shell.execute_reply":"2024-01-13T19:20:24.749873Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"emotion_type\nfear       800\nangry      800\ndisgust    800\nneutral    800\nsad        800\nps         800\nhappy      800\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Feature Extraction using MFCC\n# y is data and sr is sampling rate\ndef extract_mfcc(filename):\n    y, sr = librosa.load(filename, duration=3, offset=0.5)\n    mfcc= np.mean(librosa.feature.mfcc(y=y,sr=sr,n_mfcc=40).T, axis =0)\n    return mfcc\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-13T19:20:27.046505Z","iopub.execute_input":"2024-01-13T19:20:27.047676Z","iopub.status.idle":"2024-01-13T19:20:27.054231Z","shell.execute_reply.started":"2024-01-13T19:20:27.047627Z","shell.execute_reply":"2024-01-13T19:20:27.053003Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"extract_mfcc(df['input_path'][0])","metadata":{"execution":{"iopub.status.busy":"2024-01-13T19:20:29.430941Z","iopub.execute_input":"2024-01-13T19:20:29.431335Z","iopub.status.idle":"2024-01-13T19:20:43.473195Z","shell.execute_reply.started":"2024-01-13T19:20:29.431306Z","shell.execute_reply":"2024-01-13T19:20:43.471640Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"array([-285.73727   ,   85.78295   ,   -2.1689112 ,   22.125532  ,\n        -14.757395  ,   11.051346  ,   12.412449  ,   -3.0002618 ,\n          1.0844991 ,   11.078272  ,  -17.41966   ,   -8.093213  ,\n          6.5879726 ,   -4.2209535 ,   -9.15508   ,    3.52148   ,\n        -13.186381  ,   14.078853  ,   19.66973   ,   22.725618  ,\n         32.57464   ,   16.325035  ,   -3.8427293 ,    0.89629656,\n        -11.239262  ,    6.653462  ,   -2.5883696 ,   -7.7140164 ,\n        -10.941658  ,   -2.4007547 ,   -5.281288  ,    4.271157  ,\n        -11.202216  ,   -9.024621  ,   -3.6669848 ,    4.869744  ,\n         -1.6027985 ,    2.5600514 ,   11.454374  ,   11.233449  ],\n      dtype=float32)"},"metadata":{}}]},{"cell_type":"code","source":"# Iterating through all files and extracting features\n\nX_mfcc = df['input_path'].apply(lambda complete_path: extract_mfcc(complete_path))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T19:49:42.473810Z","iopub.execute_input":"2024-01-13T19:49:42.474221Z","iopub.status.idle":"2024-01-13T19:52:57.513623Z","shell.execute_reply.started":"2024-01-13T19:49:42.474190Z","shell.execute_reply":"2024-01-13T19:52:57.511995Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X_mfcc","metadata":{"execution":{"iopub.status.busy":"2024-01-13T19:58:41.606322Z","iopub.execute_input":"2024-01-13T19:58:41.607137Z","iopub.status.idle":"2024-01-13T19:58:41.621401Z","shell.execute_reply.started":"2024-01-13T19:58:41.607093Z","shell.execute_reply":"2024-01-13T19:58:41.620267Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0       [-285.73727, 85.78295, -2.1689112, 22.125532, ...\n1       [-348.34332, 35.193233, -3.841328, 14.658875, ...\n2       [-340.11435, 53.796444, -14.267782, 20.884027,...\n3       [-306.63422, 21.259708, -4.4110823, 6.4871554,...\n4       [-344.7548, 46.329193, -24.171413, 19.392921, ...\n                              ...                        \n5595    [-374.3952, 60.864998, 0.025059083, 8.431058, ...\n5596    [-313.96478, 39.847843, -5.6493053, -3.867575,...\n5597    [-357.54886, 77.886055, -15.224756, 2.194633, ...\n5598    [-353.1474, 101.68391, -14.175896, -12.037376,...\n5599    [-389.4595, 54.042767, 1.346998, -1.4258983, -...\nName: input_path, Length: 5600, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"# Covert df to 2D array \n\nX = [x for x in X_mfcc]\nX = np.array(X)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-13T20:04:40.106898Z","iopub.execute_input":"2024-01-13T20:04:40.107353Z","iopub.status.idle":"2024-01-13T20:04:40.123138Z","shell.execute_reply.started":"2024-01-13T20:04:40.107317Z","shell.execute_reply":"2024-01-13T20:04:40.121912Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(5600, 40)"},"metadata":{}}]},{"cell_type":"code","source":"# Use lSTM model\n# input split\nX= np.expand_dims(X, -1)\nX.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-13T20:04:42.951343Z","iopub.execute_input":"2024-01-13T20:04:42.951755Z","iopub.status.idle":"2024-01-13T20:04:42.959454Z","shell.execute_reply.started":"2024-01-13T20:04:42.951722Z","shell.execute_reply":"2024-01-13T20:04:42.958535Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(5600, 40, 1)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nenc = OneHotEncoder()\ny = enc.fit_transform(df[['emotion_type']])\n# y[0]\ny = y.toarray()","metadata":{"execution":{"iopub.status.busy":"2024-01-13T20:27:48.920543Z","iopub.execute_input":"2024-01-13T20:27:48.920980Z","iopub.status.idle":"2024-01-13T20:27:48.934240Z","shell.execute_reply.started":"2024-01-13T20:27:48.920947Z","shell.execute_reply":"2024-01-13T20:27:48.932788Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Create LSTM model**","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential \nfrom keras.layers import Dense, LSTM, Dropout\n\nmodel = Sequential([\n    LSTM(123, return_sequences = False, input_shape=(40,1)),\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n    Dense(32, activation='relu'),\n    Dropout(0.2),\n    Dense(7,activation=\"softmax\") # 7 for 7 categories\n])\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-13T20:27:51.447735Z","iopub.execute_input":"2024-01-13T20:27:51.448114Z","iopub.status.idle":"2024-01-13T20:27:51.841224Z","shell.execute_reply.started":"2024-01-13T20:27:51.448085Z","shell.execute_reply":"2024-01-13T20:27:51.839951Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n lstm_2 (LSTM)               (None, 123)               61500     \n                                                                 \n dense_4 (Dense)             (None, 64)                7936      \n                                                                 \n dropout_3 (Dropout)         (None, 64)                0         \n                                                                 \n dense_5 (Dense)             (None, 32)                2080      \n                                                                 \n dropout_4 (Dropout)         (None, 32)                0         \n                                                                 \n dense_6 (Dense)             (None, 7)                 231       \n                                                                 \n=================================================================\nTotal params: 71747 (280.26 KB)\nTrainable params: 71747 (280.26 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Train the model**\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, y, random_state=0, shuffle=True)\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-13T21:18:39.710430Z","iopub.execute_input":"2024-01-13T21:18:39.710843Z","iopub.status.idle":"2024-01-13T21:18:39.723490Z","shell.execute_reply.started":"2024-01-13T21:18:39.710812Z","shell.execute_reply":"2024-01-13T21:18:39.721965Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"((4200, 40, 1), (4200, 7), (1400, 40, 1), (1400, 7))"},"metadata":{}}]},{"cell_type":"code","source":"history = model.fit(x_train,y_train,validation_data=(x_test,y_test), epochs =100, batch_size=512,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T21:22:23.192793Z","iopub.execute_input":"2024-01-13T21:22:23.193362Z","iopub.status.idle":"2024-01-13T21:25:45.187474Z","shell.execute_reply.started":"2024-01-13T21:22:23.193318Z","shell.execute_reply":"2024-01-13T21:25:45.186310Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Epoch 1/100\n9/9 [==============================] - 2s 207ms/step - loss: 2.6974e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9971\nEpoch 2/100\n9/9 [==============================] - 2s 198ms/step - loss: 1.9043e-04 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9971\nEpoch 3/100\n9/9 [==============================] - 2s 195ms/step - loss: 5.4173e-04 - accuracy: 0.9998 - val_loss: 0.0064 - val_accuracy: 0.9971\nEpoch 4/100\n9/9 [==============================] - 2s 195ms/step - loss: 2.0562e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9971\nEpoch 5/100\n9/9 [==============================] - 2s 195ms/step - loss: 7.5942e-04 - accuracy: 0.9998 - val_loss: 0.0059 - val_accuracy: 0.9971\nEpoch 6/100\n9/9 [==============================] - 2s 196ms/step - loss: 2.1801e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 0.9986\nEpoch 7/100\n9/9 [==============================] - 2s 195ms/step - loss: 3.6021e-04 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 0.9971\nEpoch 8/100\n9/9 [==============================] - 2s 196ms/step - loss: 2.2218e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9971\nEpoch 9/100\n9/9 [==============================] - 2s 195ms/step - loss: 1.9348e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9971\nEpoch 10/100\n9/9 [==============================] - 2s 196ms/step - loss: 4.9737e-04 - accuracy: 0.9998 - val_loss: 0.0094 - val_accuracy: 0.9971\nEpoch 11/100\n9/9 [==============================] - 2s 228ms/step - loss: 2.9669e-04 - accuracy: 1.0000 - val_loss: 0.0244 - val_accuracy: 0.9943\nEpoch 12/100\n9/9 [==============================] - 2s 201ms/step - loss: 2.9681e-04 - accuracy: 1.0000 - val_loss: 0.0192 - val_accuracy: 0.9957\nEpoch 13/100\n9/9 [==============================] - 2s 200ms/step - loss: 9.3557e-04 - accuracy: 0.9995 - val_loss: 0.0159 - val_accuracy: 0.9971\nEpoch 14/100\n9/9 [==============================] - 2s 198ms/step - loss: 5.8091e-04 - accuracy: 0.9998 - val_loss: 0.0021 - val_accuracy: 0.9986\nEpoch 15/100\n9/9 [==============================] - 2s 195ms/step - loss: 3.6364e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9986\nEpoch 16/100\n9/9 [==============================] - 2s 207ms/step - loss: 2.1704e-04 - accuracy: 1.0000 - val_loss: 1.6981e-04 - val_accuracy: 1.0000\nEpoch 17/100\n9/9 [==============================] - 2s 209ms/step - loss: 3.5106e-04 - accuracy: 1.0000 - val_loss: 1.0568e-04 - val_accuracy: 1.0000\nEpoch 18/100\n9/9 [==============================] - 2s 197ms/step - loss: 2.1850e-04 - accuracy: 1.0000 - val_loss: 3.9462e-04 - val_accuracy: 1.0000\nEpoch 19/100\n9/9 [==============================] - 2s 199ms/step - loss: 4.3969e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9986\nEpoch 20/100\n9/9 [==============================] - 2s 190ms/step - loss: 5.3065e-04 - accuracy: 0.9998 - val_loss: 0.0014 - val_accuracy: 0.9986\nEpoch 21/100\n9/9 [==============================] - 2s 193ms/step - loss: 4.5347e-04 - accuracy: 0.9998 - val_loss: 0.0017 - val_accuracy: 0.9986\nEpoch 22/100\n9/9 [==============================] - 2s 197ms/step - loss: 2.7283e-04 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9986\nEpoch 23/100\n9/9 [==============================] - 2s 202ms/step - loss: 9.1723e-05 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 0.9986\nEpoch 24/100\n9/9 [==============================] - 2s 194ms/step - loss: 1.2429e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9986\nEpoch 25/100\n9/9 [==============================] - 2s 195ms/step - loss: 1.8236e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9986\nEpoch 26/100\n9/9 [==============================] - 2s 192ms/step - loss: 8.9804e-05 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9986\nEpoch 27/100\n9/9 [==============================] - 2s 194ms/step - loss: 1.4389e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9971\nEpoch 28/100\n9/9 [==============================] - 2s 194ms/step - loss: 2.2118e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9971\nEpoch 29/100\n9/9 [==============================] - 2s 232ms/step - loss: 3.6181e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9986\nEpoch 30/100\n9/9 [==============================] - 2s 194ms/step - loss: 3.9712e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9986\nEpoch 31/100\n9/9 [==============================] - 2s 198ms/step - loss: 1.6311e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9986\nEpoch 32/100\n9/9 [==============================] - 2s 195ms/step - loss: 8.4601e-04 - accuracy: 0.9998 - val_loss: 0.0380 - val_accuracy: 0.9921\nEpoch 33/100\n9/9 [==============================] - 2s 194ms/step - loss: 0.0043 - accuracy: 0.9993 - val_loss: 0.0098 - val_accuracy: 0.9986\nEpoch 34/100\n9/9 [==============================] - 2s 201ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.0491 - val_accuracy: 0.9950\nEpoch 35/100\n9/9 [==============================] - 2s 192ms/step - loss: 0.0206 - accuracy: 0.9950 - val_loss: 0.1074 - val_accuracy: 0.9886\nEpoch 36/100\n9/9 [==============================] - 2s 188ms/step - loss: 0.0797 - accuracy: 0.9879 - val_loss: 0.0866 - val_accuracy: 0.9836\nEpoch 37/100\n9/9 [==============================] - 2s 195ms/step - loss: 0.0153 - accuracy: 0.9943 - val_loss: 0.0074 - val_accuracy: 0.9979\nEpoch 38/100\n9/9 [==============================] - 2s 194ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0191 - val_accuracy: 0.9921\nEpoch 39/100\n9/9 [==============================] - 2s 195ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0089 - val_accuracy: 0.9979\nEpoch 40/100\n9/9 [==============================] - 2s 201ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.0047 - val_accuracy: 0.9986\nEpoch 41/100\n9/9 [==============================] - 2s 196ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.0048 - val_accuracy: 0.9986\nEpoch 42/100\n9/9 [==============================] - 2s 198ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\nEpoch 43/100\n9/9 [==============================] - 2s 198ms/step - loss: 6.5552e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\nEpoch 44/100\n9/9 [==============================] - 2s 197ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 2.5304e-04 - val_accuracy: 1.0000\nEpoch 45/100\n9/9 [==============================] - 2s 196ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 1.1448e-04 - val_accuracy: 1.0000\nEpoch 46/100\n9/9 [==============================] - 2s 202ms/step - loss: 6.4698e-04 - accuracy: 1.0000 - val_loss: 1.5202e-04 - val_accuracy: 1.0000\nEpoch 47/100\n9/9 [==============================] - 2s 221ms/step - loss: 6.8172e-04 - accuracy: 1.0000 - val_loss: 1.2927e-04 - val_accuracy: 1.0000\nEpoch 48/100\n9/9 [==============================] - 2s 206ms/step - loss: 5.9742e-04 - accuracy: 1.0000 - val_loss: 7.0861e-05 - val_accuracy: 1.0000\nEpoch 49/100\n9/9 [==============================] - 2s 198ms/step - loss: 7.2377e-04 - accuracy: 0.9998 - val_loss: 1.2067e-04 - val_accuracy: 1.0000\nEpoch 50/100\n9/9 [==============================] - 2s 193ms/step - loss: 6.5106e-04 - accuracy: 1.0000 - val_loss: 1.2279e-04 - val_accuracy: 1.0000\nEpoch 51/100\n9/9 [==============================] - 2s 199ms/step - loss: 5.5439e-04 - accuracy: 1.0000 - val_loss: 1.4975e-04 - val_accuracy: 1.0000\nEpoch 52/100\n9/9 [==============================] - 2s 188ms/step - loss: 4.9855e-04 - accuracy: 1.0000 - val_loss: 1.3945e-04 - val_accuracy: 1.0000\nEpoch 53/100\n9/9 [==============================] - 2s 194ms/step - loss: 2.7962e-04 - accuracy: 1.0000 - val_loss: 1.0952e-04 - val_accuracy: 1.0000\nEpoch 54/100\n9/9 [==============================] - 2s 194ms/step - loss: 3.9529e-04 - accuracy: 1.0000 - val_loss: 8.0952e-05 - val_accuracy: 1.0000\nEpoch 55/100\n9/9 [==============================] - 2s 196ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 4.6440e-05 - val_accuracy: 1.0000\nEpoch 56/100\n9/9 [==============================] - 2s 195ms/step - loss: 4.4769e-04 - accuracy: 1.0000 - val_loss: 5.6589e-05 - val_accuracy: 1.0000\nEpoch 57/100\n9/9 [==============================] - 2s 200ms/step - loss: 5.3285e-04 - accuracy: 0.9998 - val_loss: 5.0943e-05 - val_accuracy: 1.0000\nEpoch 58/100\n9/9 [==============================] - 2s 197ms/step - loss: 5.8848e-04 - accuracy: 1.0000 - val_loss: 4.2875e-05 - val_accuracy: 1.0000\nEpoch 59/100\n9/9 [==============================] - 2s 192ms/step - loss: 3.2706e-04 - accuracy: 1.0000 - val_loss: 5.2781e-05 - val_accuracy: 1.0000\nEpoch 60/100\n9/9 [==============================] - 2s 193ms/step - loss: 4.7519e-04 - accuracy: 1.0000 - val_loss: 6.8181e-05 - val_accuracy: 1.0000\nEpoch 61/100\n9/9 [==============================] - 2s 197ms/step - loss: 5.2598e-04 - accuracy: 1.0000 - val_loss: 5.8011e-05 - val_accuracy: 1.0000\nEpoch 62/100\n9/9 [==============================] - 2s 194ms/step - loss: 2.2688e-04 - accuracy: 1.0000 - val_loss: 5.2643e-05 - val_accuracy: 1.0000\nEpoch 63/100\n9/9 [==============================] - 2s 199ms/step - loss: 6.2016e-04 - accuracy: 0.9998 - val_loss: 4.3523e-05 - val_accuracy: 1.0000\nEpoch 64/100\n9/9 [==============================] - 2s 196ms/step - loss: 2.1850e-04 - accuracy: 1.0000 - val_loss: 3.8332e-05 - val_accuracy: 1.0000\nEpoch 65/100\n9/9 [==============================] - 2s 208ms/step - loss: 1.9582e-04 - accuracy: 1.0000 - val_loss: 3.6129e-05 - val_accuracy: 1.0000\nEpoch 66/100\n9/9 [==============================] - 2s 218ms/step - loss: 2.4406e-04 - accuracy: 1.0000 - val_loss: 3.6303e-05 - val_accuracy: 1.0000\nEpoch 67/100\n9/9 [==============================] - 2s 195ms/step - loss: 1.9362e-04 - accuracy: 1.0000 - val_loss: 3.7379e-05 - val_accuracy: 1.0000\nEpoch 68/100\n9/9 [==============================] - 2s 203ms/step - loss: 6.8237e-04 - accuracy: 0.9998 - val_loss: 4.2148e-05 - val_accuracy: 1.0000\nEpoch 69/100\n9/9 [==============================] - 2s 197ms/step - loss: 1.3782e-04 - accuracy: 1.0000 - val_loss: 5.7594e-05 - val_accuracy: 1.0000\nEpoch 70/100\n9/9 [==============================] - 2s 192ms/step - loss: 1.4738e-04 - accuracy: 1.0000 - val_loss: 6.4831e-05 - val_accuracy: 1.0000\nEpoch 71/100\n9/9 [==============================] - 2s 195ms/step - loss: 3.5018e-04 - accuracy: 1.0000 - val_loss: 6.9331e-05 - val_accuracy: 1.0000\nEpoch 72/100\n9/9 [==============================] - 2s 196ms/step - loss: 2.1794e-04 - accuracy: 1.0000 - val_loss: 6.5231e-05 - val_accuracy: 1.0000\nEpoch 73/100\n9/9 [==============================] - 2s 197ms/step - loss: 4.5293e-04 - accuracy: 1.0000 - val_loss: 7.5952e-05 - val_accuracy: 1.0000\nEpoch 74/100\n9/9 [==============================] - 2s 204ms/step - loss: 2.4788e-04 - accuracy: 1.0000 - val_loss: 8.0037e-05 - val_accuracy: 1.0000\nEpoch 75/100\n9/9 [==============================] - 2s 204ms/step - loss: 1.3918e-04 - accuracy: 1.0000 - val_loss: 8.0251e-05 - val_accuracy: 1.0000\nEpoch 76/100\n9/9 [==============================] - 2s 206ms/step - loss: 1.5993e-04 - accuracy: 1.0000 - val_loss: 5.7480e-05 - val_accuracy: 1.0000\nEpoch 77/100\n9/9 [==============================] - 2s 197ms/step - loss: 2.7004e-04 - accuracy: 1.0000 - val_loss: 5.3083e-05 - val_accuracy: 1.0000\nEpoch 78/100\n9/9 [==============================] - 2s 197ms/step - loss: 2.7987e-04 - accuracy: 1.0000 - val_loss: 5.8930e-05 - val_accuracy: 1.0000\nEpoch 79/100\n9/9 [==============================] - 2s 197ms/step - loss: 1.9526e-04 - accuracy: 1.0000 - val_loss: 5.8150e-05 - val_accuracy: 1.0000\nEpoch 80/100\n9/9 [==============================] - 2s 198ms/step - loss: 3.9265e-04 - accuracy: 1.0000 - val_loss: 4.0894e-05 - val_accuracy: 1.0000\nEpoch 81/100\n9/9 [==============================] - 2s 193ms/step - loss: 3.4290e-04 - accuracy: 1.0000 - val_loss: 3.3835e-05 - val_accuracy: 1.0000\nEpoch 82/100\n9/9 [==============================] - 2s 196ms/step - loss: 1.7966e-04 - accuracy: 1.0000 - val_loss: 3.8628e-05 - val_accuracy: 1.0000\nEpoch 83/100\n9/9 [==============================] - 2s 206ms/step - loss: 2.1587e-04 - accuracy: 1.0000 - val_loss: 6.8148e-05 - val_accuracy: 1.0000\nEpoch 84/100\n9/9 [==============================] - 2s 218ms/step - loss: 6.6966e-04 - accuracy: 0.9998 - val_loss: 2.3184e-04 - val_accuracy: 1.0000\nEpoch 85/100\n9/9 [==============================] - 2s 202ms/step - loss: 1.9344e-04 - accuracy: 1.0000 - val_loss: 6.1746e-04 - val_accuracy: 1.0000\nEpoch 86/100\n9/9 [==============================] - 2s 198ms/step - loss: 1.3230e-04 - accuracy: 1.0000 - val_loss: 9.1722e-04 - val_accuracy: 1.0000\nEpoch 87/100\n9/9 [==============================] - 2s 196ms/step - loss: 3.2456e-04 - accuracy: 1.0000 - val_loss: 5.9712e-05 - val_accuracy: 1.0000\nEpoch 88/100\n9/9 [==============================] - 2s 194ms/step - loss: 2.5323e-04 - accuracy: 1.0000 - val_loss: 3.5966e-05 - val_accuracy: 1.0000\nEpoch 89/100\n9/9 [==============================] - 2s 200ms/step - loss: 2.7813e-04 - accuracy: 1.0000 - val_loss: 3.6017e-05 - val_accuracy: 1.0000\nEpoch 90/100\n9/9 [==============================] - 2s 201ms/step - loss: 1.4580e-04 - accuracy: 1.0000 - val_loss: 4.8635e-05 - val_accuracy: 1.0000\nEpoch 91/100\n9/9 [==============================] - 2s 204ms/step - loss: 2.4372e-04 - accuracy: 1.0000 - val_loss: 9.1823e-05 - val_accuracy: 1.0000\nEpoch 92/100\n9/9 [==============================] - 2s 197ms/step - loss: 2.2165e-04 - accuracy: 1.0000 - val_loss: 2.8365e-04 - val_accuracy: 1.0000\nEpoch 93/100\n9/9 [==============================] - 2s 194ms/step - loss: 1.5933e-04 - accuracy: 1.0000 - val_loss: 3.8878e-04 - val_accuracy: 1.0000\nEpoch 94/100\n9/9 [==============================] - 2s 197ms/step - loss: 2.4954e-04 - accuracy: 1.0000 - val_loss: 4.4269e-04 - val_accuracy: 1.0000\nEpoch 95/100\n9/9 [==============================] - 2s 198ms/step - loss: 1.2550e-04 - accuracy: 1.0000 - val_loss: 2.9945e-04 - val_accuracy: 1.0000\nEpoch 96/100\n9/9 [==============================] - 2s 198ms/step - loss: 2.5822e-04 - accuracy: 1.0000 - val_loss: 1.1565e-04 - val_accuracy: 1.0000\nEpoch 97/100\n9/9 [==============================] - 2s 194ms/step - loss: 1.7621e-04 - accuracy: 1.0000 - val_loss: 8.6621e-05 - val_accuracy: 1.0000\nEpoch 98/100\n9/9 [==============================] - 2s 199ms/step - loss: 2.9381e-04 - accuracy: 1.0000 - val_loss: 7.2266e-05 - val_accuracy: 1.0000\nEpoch 99/100\n9/9 [==============================] - 2s 203ms/step - loss: 1.1420e-04 - accuracy: 1.0000 - val_loss: 6.8755e-05 - val_accuracy: 1.0000\nEpoch 100/100\n9/9 [==============================] - 2s 204ms/step - loss: 2.6680e-04 - accuracy: 1.0000 - val_loss: 4.8077e-05 - val_accuracy: 1.0000\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"Accuracy of our model on test data : \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")\n\nepochs = [i for i in range(50)]\nfig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\ntest_acc = history.history['val_accuracy']\ntest_loss = history.history['val_loss']\n\nfig.set_size_inches(20,6)\nax[0].plot(epochs , train_loss , label = 'Training Loss')\nax[0].plot(epochs , test_loss , label = 'Testing Loss')\nax[0].set_title('Training & Testing Loss')\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\n\nax[1].plot(epochs , train_acc , label = 'Training Accuracy')\nax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\nax[1].set_title('Training & Testing Accuracy')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-13T21:30:40.864856Z","iopub.execute_input":"2024-01-13T21:30:40.865400Z","iopub.status.idle":"2024-01-13T21:30:42.271194Z","shell.execute_reply.started":"2024-01-13T21:30:40.865364Z","shell.execute_reply":"2024-01-13T21:30:42.269177Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"44/44 [==============================] - 1s 17ms/step - loss: 4.8077e-05 - accuracy: 1.0000\nAccuracy of our model on test data :  100.0 %\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[55], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m fig\u001b[38;5;241m.\u001b[39mset_size_inches(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m6\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTraining Loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(epochs , test_loss , label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m ax[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining & Testing Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1447\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1688\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (100,)"],"ename":"ValueError","evalue":"x and y must have same first dimension, but have shapes (50,) and (100,)","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 2000x600 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"pred_test = model.predict(x_test)\ny_pred = enc.inverse_transform(pred_test)\n\ny_test = enc.inverse_transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T21:30:47.810880Z","iopub.execute_input":"2024-01-13T21:30:47.811292Z","iopub.status.idle":"2024-01-13T21:30:48.671250Z","shell.execute_reply.started":"2024-01-13T21:30:47.811259Z","shell.execute_reply":"2024-01-13T21:30:48.669748Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"44/44 [==============================] - 1s 17ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.DataFrame(columns=['Predicted Labels', 'Actual Labels'])\ndf['Predicted Labels'] = y_pred.flatten()\ndf['Actual Labels'] = y_test.flatten()\n\ndf.head(100)","metadata":{"execution":{"iopub.status.busy":"2024-01-13T21:31:02.011053Z","iopub.execute_input":"2024-01-13T21:31:02.011514Z","iopub.status.idle":"2024-01-13T21:31:02.036297Z","shell.execute_reply.started":"2024-01-13T21:31:02.011477Z","shell.execute_reply":"2024-01-13T21:31:02.034609Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"   Predicted Labels Actual Labels\n0           disgust       disgust\n1           disgust       disgust\n2           neutral       neutral\n3             angry         angry\n4             angry         angry\n..              ...           ...\n95              sad           sad\n96               ps            ps\n97            angry         angry\n98          neutral       neutral\n99            happy         happy\n\n[100 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Predicted Labels</th>\n      <th>Actual Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>disgust</td>\n      <td>disgust</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>disgust</td>\n      <td>disgust</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>neutral</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>angry</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>angry</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>sad</td>\n      <td>sad</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>ps</td>\n      <td>ps</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>angry</td>\n      <td>angry</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>neutral</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>happy</td>\n      <td>happy</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-01-13T21:31:07.001568Z","iopub.execute_input":"2024-01-13T21:31:07.002002Z","iopub.status.idle":"2024-01-13T21:31:07.084533Z","shell.execute_reply.started":"2024-01-13T21:31:07.001968Z","shell.execute_reply":"2024-01-13T21:31:07.083089Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n       angry       1.00      1.00      1.00       197\n     disgust       1.00      1.00      1.00       207\n        fear       1.00      1.00      1.00       203\n       happy       1.00      1.00      1.00       200\n     neutral       1.00      1.00      1.00       198\n          ps       1.00      1.00      1.00       208\n         sad       1.00      1.00      1.00       187\n\n    accuracy                           1.00      1400\n   macro avg       1.00      1.00      1.00      1400\nweighted avg       1.00      1.00      1.00      1400\n\n","output_type":"stream"}]}]}